#include "../headfile.h"

//影响并发代码性能的因素
//硬件
/* 当多于处理器数量个线程在运行的时候(都没有阻塞或等待),应用将会浪费处理器的运算时间在线程间进行切换
 * 这种情况发生时称其为超额认购(oversubscription)
 * 为了扩展应用线程的数量,且与硬件所支持的并发线程数量一致,C++标准线程库提供了std::thread::hardware_concurrency()
 * 使用这个函数就能知道在给定硬件上可以扩展的线程数量
 * 但多线程同时调用std::thread::hardware_concurrency()函数来对线程数量进行扩展,这样将导致庞大的超额认购
 * std::async()能避免这个问题
 * 随着处理器数量的增加,另一个问题就会来影响性能:多个处理器尝试访问同一个数据
 */

//数据争抢
/* 当两个线程并发的在不同处理器上执行,并且对同一数据进行读取,通常不会出现问题
 * 因为数据将会拷贝到每个线程的缓存中,并且让两个处理器同时进行处理
 * 当有线程对数据进行修改的时候,这个修改需要更新到其他核芯的缓存中去,就要耗费一定的时间
 * 这样的修改可能会让第二个处理器停下来,等待硬件内存更新缓存中的数据
 * 不过根据CPU指令,这是一个特别特别慢的操作,相当于执行成百上千个独立指令
 */
std::atomic<unsigned long> counter(0);
void processing_loop() {
    while (counter.fetch_add(1, std::memory_order_relaxed) < 100000000) {
        do_something();
    }
}
/* 如果do_something()足够短,或有很多处理器来对这段代码进行处理时,处理器将会互相等待
 * 一个处理器准备更新这个值,另一个处理器正在修改这个值,所以该处理器就需要等待第二个处理器更新完成
 * 并且完成更新传递时才能执行更新,这种情况被称为高竞争(high contention)
 * 如果处理器很少需要互相等待,这种情况就是低竞争(low contention)
 * 同时counter变量是全局的,循环调用将在每个缓存中传递若干次
 * 当新增加的处理器时,counter变量必须要在缓存内做一份拷贝,再改变自己的值,这就叫做乒乓缓存(cache ping-pong)
 * 这种情况会对应用的性能有着重大的影响,当一个处理器因为等待缓存转移而停止运行时,这个处理器就不能做任何事情
 */
std::mutex mtx;
int data = 1;
void processing_loop_with_mutex() {
    while (true)   {
        std::lock_guard<std::mutex> lk(mtx);
        if (done_processing(data)) break;
    }
}
/* 如果需要在循环中放置一个互斥量,那么代码就和之前从数据访问的差不多了
 * 为了锁住互斥量,另一个线程必须将数据进行转移,就能弥补处理器的互斥性,并且对数据进行修改
 * 当这个过程完成时,将会再次对互斥量进行修改,并对线程进行解锁,之后互斥数据将会传递到下一个需要互斥量的线程上去
 * 转移时间就是第二个线程等待第一个线程释放互斥量的时间
 * 互斥量的竞争通常不同于原子操作的竞争,互斥量通常使用操作系统级别的序列化线程,而非处理器级别的
 * 如果有足够的线程去执行任务,有线程在等待互斥量时,操作系统会安排其他线程来执行任务
 * 而处理器只会在其他线程运行在目标处理器上时,从而让该处理器停止工作
 * 一个很少更新的数据结构可以被一个 单作者,多读者 的互斥量保护
 * 因为所有线程访问数据(即使是读者线程)都会对互斥量进行修改,随着处理器对数据的访问次数增加
 * 对于互斥量的竞争就会增加,并且持有互斥量的缓存行将会在核芯中进行转移,因此会增加不良的锁获取和释放次数
 * 减少两个线程对同一个内存位置的竞争可以避免乒乓缓存
 * 但即使给定内存位置被一个线程所访问,可能还是会有乒乓缓存存在,是因为另一种叫做伪共享(false sharing)的效应
 */

//伪共享
/* 假设有一个int类型的数组,并且有一组线程可以访问数组中的元素,且对数组的访问很频繁(包括更新)
 * 通常int类型的大小要小于一个缓存行,因此同一个缓存行中可以存储多个数据项
 * 因此即使每个线程都能对数据中的成员进行访问,硬件缓存还是会产生乒乓缓存
 * 每当线程访问0号数据项,并对其值进行更新时,缓存行的所有权就需要转移给执行该线程的处理器
 * 这仅是为了更新1号数据项的线程获取1号线程的所有权(缓存行是共享的,即使没有数据存在)
 * 这个问题的解决办法就是对数据进行构造,让同一线程访问的数据项存在临近的内存中(就像是放在同一缓存行中)
 * 这样那些能被独立线程访问的数据将分布在相距很远的地方,并且可能是存储在不同的缓存行
 * 伪共享发生的原因:某个线程所要访问的数据过于接近另一线程的数据
 *
 * 如果系统中的线程数量要比核芯多,每个核上都要运行多个线程(任务切换 task switching)
 * 这会增加缓存的压力,为了避免伪共享,努力让不同线程访问不同缓存行
 * 当处理器切换线程时,就要对不同内存行上的数据进行重新加载(当不同线程使用的数据跨越了多个缓存行时)
 * 而非对缓存中的数据保持原样(当线程中的数据都在同一缓存行时)
 *
 * 频繁的任务切换
 * 多线程系统中,通常线程的数量要多于处理的数量
 * 不过线程经常会花费时间来等待外部I/O完成,或被互斥量阻塞,或等待条件变量等等
 * 所以等待不是问题,应用使用额外的线程来完成有用的工作,而非让线程在处理器处以闲置状态时继续等待。
 * 如果有很多额外线程,就会有很多线程准备执行,而且数量远远大于可用处理器的数量,操作系统就会忙于切换任务,以确保每个任务都有时间运行
 */
//C++17并准在头文件<new>中定义了std::hardware_destructive_interference_size
//它指定了当前编译目标可能共享的连续字节的最大数目,如果确保数据间隔大于等于这个字节数,就不会有错误的共享存在了
//C++17在头文件<new>中指定了一个常数std::hardware_constructive_interference_size
//这是同一高速缓存行上的连续字节的最大数目(如果对齐),当可以将所需的数据放在这个字节数内,就能提高缓存命中率

/* 
 * 为了优化性能,需要仔细考虑数据访问的模式
 * 1.尝试调整数据在线程间的分布,能让同一线程中的数据紧密联系在一起
 * 2.尝试减少线程上所需的数据量
 * 3.尝试让不同线程访问不同的存储位置以避免伪共享
 * 三个方法用于想要优化数据结构的数据访问模式
 * 对于一个数组来说,访问连续的元素是最好的方式,这将会减少缓存的刷新,并且降低伪共享的概率
 */